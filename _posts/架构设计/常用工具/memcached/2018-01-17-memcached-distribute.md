---
title: memcached分布式缓存
tags: [memecached]
---

由于单台Memcached服务器的内存容量是有限的，并且单台也存在单点故障。因此，就需要将多个memcached服务组合起来提供服务。

注：只要涉及到分布式都会使用的hash算法，memcached服务器集群一般会选择hash或一致性hash算法。

### Cache服务集群使用常规负责均衡模式的问题

1）问题描述：

如果有三台memcached服务器，那么这三台服务器缓存的内容是不同的。负载均衡服务器一般是针对集群中的应用服务器，因为应用服务器是无状态的，集群中的所有服务器都提供相同的服务。因此，负载均衡只需要将请求均衡的分配即可，无须考虑服务器的差异性。而集群中的缓存服务器存储的内容是不一样的。

2）解决思路：

负载均衡需要使用hash算法来实现缓存数据的查找。存储数据时也是有这种hash算法，将数据分别存储在不同的缓存服务器上。一个请求被负载均衡收到了，计算获取其hash值，可以通过hash值与服务器数量取模操作来确定服务器位置。如有3台服务器，请求到达负载均衡服务器，根据请求的内容计算出一个hash值，用这个hash值对3取余，获取一个数值（0，1，2），如果为0，则定位到0号缓存服务器上。

这种方式的实现是有问题的，如果某个缓存服务器宕机了，或者在缓存中加入了新的服务器，那么需要重新计算hash，重新分配缓存内容。因此，会造成大量的数据缓存失效，甚至可能会影响到后端数据库的压力。

注：这种方式一般是由客户端程序访问缓存来实现的，当然负载均衡上也有此类算法。

3）解决方法：

如何使用缓存服务器集群，则不建议在缓存服务器前再配置负载均衡，触发负载均衡能够支持相应的hash算法。一般来将都是在应用服务器上完成hash算法的计算，从而确定出缓存服务器的位置（程序实现缓存的定位），程序直接从缓存服务器上访问获取数据即可。

a.针对已用户为主的网站来讲，每个用户都有userid，使用userid作为hash计算的key来定位缓存服务器。

注：这个方法是有缺陷的，有些业务缓存的数据是与用户无关的，可能造成每个服务器都会缓存这部分数据，造成内存空间的浪费，甚至带来数据不一致的情况。

b.使用url_hash方式，在应用服务器上通过程序以及URL_HASH，去访问memcached服务器，所有的memcached服务器的地址池可以简单的配置到应用程序的配置文件中。

c.可以使用nginx的分支tengine实现对mc的负载均衡（该负载均衡服务器支持hash），通过负载均衡来确定缓存服务器的位置。

### 实例

有1TB的数据需要进行缓存，那么单台缓存服务器是没有这么大的内存的空间，因此，必定要使用分布式缓存来实现。

1）分布式缓存的设计思想

a.每一台MC服务器的内容都是不一样的，这些服务器内容加起来接近整个数据库的容量。

b.通过在客户端程序或者MC的负载均衡服务器上用hash算法，让同一内容的访问分配到同一个MC服务器上。

c.普通的hash算法对于节点宕机会带来大量的缓存数据失效（缓存数据重新分配），可能会引起数据库雪崩效应。

d.一致性hash算法（还可以带虚拟节点）可以让节点的宕机对节点的缓存数据失效降到最低。

### 分布时memcached缓存集群调度算法

1）取模计算hash

优点：简单、分散性优秀

缺点：添加/移除服务器时，缓存重组代价巨大，影响命中率

2）一致性hash算法

参考：http://blog.csdn.net/cywosp/article/details/23397179/

a.环形Hash空间

按照常用的hash算法来将对应的key哈希到一个具有2^32次方个桶的空间中，即0~(2^32)-1的数字空间中。

![](/images/architecture/memcached/consistenthashing1.png)

b.计算数据的hash值并映射到环上

把数据通过一定的hash算法处理后映射到环上，将object1、object2、object3、object4四个对象通过特定的Hash函数计算出对应的key值，然后散列到Hash环上。

```
    Hash(object1) = key1；
    Hash(object2) = key2；
    Hash(object3) = key3；
    Hash(object4) = key4；
```

![](/images/architecture/memcached/consistenthashing2.png)

c.将缓存服务器节点也映射到环上

将机器通过hash算法映射到环上，在采用一致性哈希算法的分布式集群中将新的机器加入，其原理是通过使用与对象存储一样的Hash算法将机器也映射到环中（映射机器时尽量使集群中的机器更分散，保证每台服务器的压力接近平衡，即分散在环上的距离尽量相等），然后以顺时针的方向计算，将所有对象存储到离自己最近的机器中。

假设现在有NODE1，NODE2，NODE3三台机器，通过Hash算法得到对应的KEY值，映射到环中。对象与机器处于同一哈希空间中，这样按顺时针转动object1存储到了NODE1中，object3存储到了NODE2中，object2、object4存储到了NODE3中。在这样的部署环境中，hash环是不会变更的，因此，通过算出对象的hash值就能快速的定位到对应的机器中，这样就能找到对象真正的存储位置了。

```
Hash(NODE1) = KEY1;
Hash(NODE2) = KEY2;
Hash(NODE3) = KEY3;
```

![](/images/architecture/memcached/consistenthashing3.png)

注：映射主机使用的hash算法与数据hash算法是一致的，便于通过比较hash值，将数据映射到最近的服务器上。

注2：数据映射时规定顺时针映射数据到服务器。

d.服务器节点删除

如果NODE2出现故障被删除了，那么按照顺时针迁移的方法，object3将会被迁移到NODE3中，这样仅仅是object3的映射位置发生了变化，其它的对象没有任何的改动。

![](/images/architecture/memcached/consistenthashing4.png)

注：即使缓存数据重新hash后，影响节点数据也不会太多。node1和node3服务器中的缓存依然有效。

e.服务器节点添加

如果往集群中添加一个新的节点NODE4，通过对应的哈希算法得到KEY4，并映射到环中.通过按顺时针迁移的规则，那么object2被迁移到了NODE4中，其它对象还保持这原有的存储位置。

![](/images/architecture/memcached/consistenthashing5.png)

总结：通过对节点的添加和删除的分析，一致性哈希算法在保持了单调性的同时，还是数据的迁移达到了最小，这样的算法对分布式集群来说是非常合适的，避免了大量数据迁移，减小了服务器的的压力。

3）一致性hash算法中加入虚拟节点

加入虚拟节点的目的是平衡个服务器节点的数据缓存压力。

虚拟节点（virtual node）是实际节点（机器）在hash空间的复制品（replica），一实际个节点（机器）对应了若干个虚拟节点，这个对应个数即为复制个数，虚拟节点在hash空间中以hash值排列，即与实际节点一样使用一致性hash算法排列在环中。

![](/images/architecture/memcached/consistenthashing6.png)

虚拟节点和真实节点的对应关系是解决缓存问题的重点。

解决方法：

虚拟节点的hash计算可以采用对应节点的IP地址加数字后缀的方式。例如假设NODE1的IP地址为192.168.1.100。引入虚拟节点前，计算 cache A 的 hash 值：

```
Hash(“192.168.1.100”);
```

引入虚拟节点后，计算“虚拟节”点NODE1-1和NODE1-2的hash值：

```
Hash(192.168.1.100#1); // NODE1-1
Hash(192.168.1.100#2); // NODE1-2
```

注：通过ip地址能清楚数据存放的服务器地址。